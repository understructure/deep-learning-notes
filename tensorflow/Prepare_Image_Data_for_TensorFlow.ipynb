{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set three variables for directories in the next cell.  Note that there shouldn't be a trailing slash after any of them, and these should be full paths to the original images, the directory to save the pickled numpy arrays, and the directory to save the images created from the pickle files, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# original images directory\n",
    "source_img_dir = \"/Users/mcloney/Downloads/image-recognition-eval-master/images/original/item\"\n",
    "# (existing, preferably empty) directory for pickle file output\n",
    "pickle_dir = \"/Users/mcloney/Desktop/pickles\"\n",
    "# Directory to place the unpickled images\n",
    "out_dir = \"/Users/mcloney/Desktop/reconstituted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "# image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def vectorize_image(folder, image, pixel_depth=None):\n",
    "    \n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "        if not pixel_depth:\n",
    "            pixel_depth = 255.0\n",
    "\n",
    "        # normalize all values to between -0.5 and 0.5\n",
    "        image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "\n",
    "        return image_data\n",
    "    except IOError as e:\n",
    "        print('Could not read:', image_file, ':', e, '- skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unnormalize_image(X, pixel_depth):\n",
    "    x = (X * pixel_depth) + pixel_depth / 2\n",
    "    return x.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstitute_image(in_pickle, out_image):\n",
    "    with open(in_pickle, 'rb') as f:\n",
    "        pkl = pickle.load(f)\n",
    "\n",
    "    u_array = unnormalize_image(pkl, 255)\n",
    "    scipy.misc.toimage(u_array).save(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_all_images(img_dir, img_file_list, pickle_dir):\n",
    "    for img in img_file_list:\n",
    "        print(\"Processing {}\".format(img))\n",
    "        pickled = vectorize_image(img_dir, img)\n",
    "        outfile = \".\".join([img.replace(\".\", \"_\"), \"pickle\"])\n",
    "        with open(os.sep.join([pickle_dir, outfile]), 'wb') as f:\n",
    "            pickle.dump(pickled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle_all_images(pickle_dir, img_out_dir):\n",
    "    for pfile in os.listdir(pickle_dir):\n",
    "        if pfile[-7:].lower() == \".pickle\":\n",
    "            print(\"Processing {}\".format(pfile))\n",
    "            # nasty I know but it works :)\n",
    "            file_ext = pfile[::-1][7:].split(\"_\")[0][::-1]\n",
    "            pkl_full_path = os.sep.join([pickle_dir, pfile])\n",
    "            outfile = os.sep.join([img_out_dir, \".\".join([pfile.replace(\".\", \"_\"), file_ext])])\n",
    "            # print(\"reconstituting {} to {}\".format(pkl_full_path, outfile))\n",
    "            reconstitute_image(pkl_full_path, outfile)\n",
    "        else:\n",
    "            print(\"{} is not a pickle file, ignoring\".format(pfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "BEGIN PICKLING\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Processing black-rim-glasses.jpg\n",
      "Processing cello.jpg\n",
      "Processing desktv.jpeg\n",
      "Processing dogflowers.jpeg\n",
      "Processing excavator.jpeg\n",
      "Processing fastfood.jpg\n",
      "Processing fish-real-1.jpg\n",
      "Processing fish-real-2.jpg\n",
      "Processing fish-real-held.jpg\n",
      "Processing fish-real-held2.jpg\n",
      "Processing ladybug.jpg\n",
      "Processing stack-of-books.jpg\n",
      "Processing tree-birch.jpg\n",
      "Processing tree-palm.jpg\n",
      "Processing tree-sugar-maple.jpg\n",
      "Processing tree-yoshino-cherry.jpg\n",
      "Processing violin.jpg\n",
      "Processing VR-headset.jpg\n",
      "Processing car.png\n",
      "Processing fish-art-1.png\n",
      "Processing guitar.png\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "BEGIN RECONSTITUTING (UNPICKLING)\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".DS_Store is not a pickle file, ignoring\n",
      "Processing black-rim-glasses_jpg.pickle\n",
      "Processing car_png.pickle\n",
      "car_png.pickle.zip is not a pickle file, ignoring\n",
      "Processing cello_jpg.pickle\n",
      "Processing desktv_jpeg.pickle\n",
      "Processing dogflowers_jpeg.pickle\n",
      "Processing excavator_jpeg.pickle\n",
      "Processing fastfood_jpg.pickle\n",
      "Processing fish-art-1_png.pickle\n",
      "Processing fish-real-1_jpg.pickle\n",
      "Processing fish-real-2_jpg.pickle\n",
      "Processing fish-real-held2_jpg.pickle\n",
      "Processing fish-real-held_jpg.pickle\n",
      "Processing guitar_png.pickle\n",
      "Processing ladybug_jpg.pickle\n",
      "Processing stack-of-books_jpg.pickle\n",
      "Processing tree-birch_jpg.pickle\n",
      "Processing tree-palm_jpg.pickle\n",
      "Processing tree-sugar-maple_jpg.pickle\n",
      "Processing tree-yoshino-cherry_jpg.pickle\n",
      "Processing violin_jpg.pickle\n",
      "Processing VR-headset_jpg.pickle\n"
     ]
    }
   ],
   "source": [
    "# MAIN CODE\n",
    "\n",
    "all_objects = os.listdir(source_img_dir)\n",
    "jpgs = [x for x in all_objects if x[-4:] == \".jpg\" or x[-5:] == \".jpeg\"]\n",
    "pngs = [x for x in all_objects if x[-4:] == \".png\"]\n",
    "jsns = [x for x in all_objects if x[-5:] == \".json\"]\n",
    "\n",
    "# just because we know this is what we're looking for here:\n",
    "assert len(jpgs) + len(pngs) == len(jsns) and len(jsns) > 0\n",
    "\n",
    "print(\"*\" * 100)\n",
    "print(\"BEGIN PICKLING\")\n",
    "print(\"*\" * 100)\n",
    "print(\"\\n\" * 2)\n",
    "pickle_all_images(source_img_dir, jpgs+pngs, pickle_dir)\n",
    "print(\"\\n\" * 5)\n",
    "print(\"*\" * 100)\n",
    "print(\"BEGIN RECONSTITUTING (UNPICKLING)\")\n",
    "print(\"*\" * 100)\n",
    "print(\"\\n\" * 5)\n",
    "unpickle_all_images(pickle_dir, out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
